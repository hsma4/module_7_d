{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Titanic survival - Dealing with imbalanced data by changing classification cut-off levels\n",
    "\n",
    "A problem with machine learning models is that they may end up biased towards the majority class, and under-predict the minority class(es).\n",
    "\n",
    "Some models (including sklearn's logistic regression) allow for thresholds of classification to be changed. This can help rebalance classification in models, especially where there is a binary classification (e.g. survived or not).\n",
    "\n",
    "Here we create a more imbalanced data set from the Titanic set, by dropping half the survivors.\n",
    "\n",
    "We vary the probability cut-off for a 'survived' classification, and examine the effect of classification probability cut-off on a range of accuracy measures.\n",
    "\n",
    "If you have worked through previous notebooks, you will spot this is the technique we used to construct a Receiver Operator Characteristic curve:\n",
    "\n",
    "https://github.com/MichaelAllen1966/1804_python_healthcare/blob/master/titanic/06_roc_sensitivity_specificity.ipynb\n",
    "\n",
    "Note: You will need to look at the help files and documentation of other model types to find whether they have options to change classification cut-off levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hide warnings (to keep notebook tidy; do not usually do this)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load modules\n",
    "\n",
    "A standard Anaconda install of Python (https://www.anaconda.com/distribution/) contains all the necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Import machine learning methods\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "The section below downloads pre-processed data, and saves it to a subfolder (from where this code is run).\n",
    "If data has already been downloaded that cell may be skipped.\n",
    "\n",
    "Code that was used to pre-process the data ready for machine learning may be found at:\n",
    "https://github.com/MichaelAllen1966/1804_python_healthcare/blob/master/titanic/01_preprocessing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_required = True\n",
    "\n",
    "if download_required:\n",
    "    \n",
    "    # Download processed data:\n",
    "    address = 'https://raw.githubusercontent.com/MichaelAllen1966/' + \\\n",
    "                '1804_python_healthcare/master/titanic/data/processed_data.csv'\n",
    "    \n",
    "    data = pd.read_csv(address)\n",
    "\n",
    "    # Create a data subfolder if one does not already exist\n",
    "    import os\n",
    "    data_directory ='./data/'\n",
    "    if not os.path.exists(data_directory):\n",
    "        os.makedirs(data_directory)\n",
    "\n",
    "    # Save data\n",
    "    data.to_csv(data_directory + 'processed_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/processed_data.csv')\n",
    "# Make all data 'float' type\n",
    "data = data.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first column is a passenger index number. We will remove this, as this is not part of the original Titanic passenger data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Passengerid (axis=1 indicates we are removing a column rather than a row)\n",
    "# We drop passenger ID as it is not original data\n",
    "\n",
    "data.drop('PassengerId', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificially reduce the number of survivors (to make data set more imbalanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle original data\n",
    "data = data.sample(frac=1.0) # Sampling with a fraction of 1.0 shuffles data\n",
    "\n",
    "# Create masks for filters\n",
    "mask_died = data['Survived'] == 0\n",
    "mask_survived = data['Survived'] == 1\n",
    "\n",
    "# Filter data\n",
    "died = data[mask_died]\n",
    "survived = data[mask_survived]\n",
    "\n",
    "# Reduce survived by half\n",
    "survived = survived.sample(frac=0.5)\n",
    "\n",
    "# Recombine data and shuffle\n",
    "data = pd.concat([died, survived])\n",
    "data = data.sample(frac=1.0) \n",
    "\n",
    "# Show average of survived\n",
    "survival_rate = data['Survived'].mean()\n",
    "print ('Proportion survived:', np.round(survival_rate,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define function to standardise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardise_data(X_train, X_test):\n",
    "    \n",
    "    # Initialise a new scaling object for normalising input data\n",
    "    sc = StandardScaler() \n",
    "\n",
    "    # Set up the scaler just on the training set\n",
    "    sc.fit(X_train)\n",
    "\n",
    "    # Apply the scaler to the training and test sets\n",
    "    train_std=sc.transform(X_train)\n",
    "    test_std=sc.transform(X_test)\n",
    "    \n",
    "    return train_std, test_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define function to measure accuracy\n",
    "\n",
    "The following is a function for multiple accuracy measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(observed, predicted):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculates a range of accuracy scores from observed and predicted classes.\n",
    "    \n",
    "    Takes two list or NumPy arrays (observed class values, and predicted class \n",
    "    values), and returns a dictionary of results.\n",
    "    \n",
    "     1) observed positive rate: proportion of observed cases that are +ve\n",
    "     2) Predicted positive rate: proportion of predicted cases that are +ve\n",
    "     3) observed negative rate: proportion of observed cases that are -ve\n",
    "     4) Predicted negative rate: proportion of predicted cases that are -ve  \n",
    "     5) accuracy: proportion of predicted results that are correct    \n",
    "     6) precision: proportion of predicted +ve that are correct\n",
    "     7) recall: proportion of true +ve correctly identified\n",
    "     8) f1: harmonic mean of precision and recall\n",
    "     9) sensitivity: Same as recall\n",
    "    10) specificity: Proportion of true -ve identified:        \n",
    "    11) positive likelihood: increased probability of true +ve if test +ve\n",
    "    12) negative likelihood: reduced probability of true +ve if test -ve\n",
    "    13) false positive rate: proportion of false +ves in true -ve patients\n",
    "    14) false negative rate: proportion of false -ves in true +ve patients\n",
    "    15) true positive rate: Same as recall\n",
    "    16) true negative rate\n",
    "    17) positive predictive value: chance of true +ve if test +ve\n",
    "    18) negative predictive value: chance of true -ve if test -ve\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Converts list to NumPy arrays\n",
    "    if type(observed) == list:\n",
    "        observed = np.array(observed)\n",
    "    if type(predicted) == list:\n",
    "        predicted = np.array(predicted)\n",
    "    \n",
    "    # Calculate accuracy scores\n",
    "    observed_positives = observed == 1\n",
    "    observed_negatives = observed == 0\n",
    "    predicted_positives = predicted == 1\n",
    "    predicted_negatives = predicted == 0\n",
    "    \n",
    "    true_positives = (predicted_positives == 1) & (observed_positives == 1)\n",
    "    \n",
    "    false_positives = (predicted_positives == 1) & (observed_positives == 0)\n",
    "    \n",
    "    true_negatives = (predicted_negatives == 1) & (observed_negatives == 1)\n",
    "    \n",
    "    accuracy = np.mean(predicted == observed)\n",
    "    \n",
    "    precision = (np.sum(true_positives) /\n",
    "                 (np.sum(true_positives) + np.sum(false_positives)))\n",
    "        \n",
    "    recall = np.sum(true_positives) / np.sum(observed_positives)\n",
    "    \n",
    "    sensitivity = recall\n",
    "    \n",
    "    f1 = 2 * ((precision * recall) / (precision + recall))\n",
    "    \n",
    "    specificity = np.sum(true_negatives) / np.sum(observed_negatives)\n",
    "    \n",
    "    positive_likelihood = sensitivity / (1 - specificity)\n",
    "    \n",
    "    negative_likelihood = (1 - sensitivity) / specificity\n",
    "    \n",
    "    false_positive_rate = 1 - specificity\n",
    "    \n",
    "    false_negative_rate = 1 - sensitivity\n",
    "    \n",
    "    true_positive_rate = sensitivity\n",
    "    \n",
    "    true_negative_rate = specificity\n",
    "    \n",
    "    positive_predictive_value = (np.sum(true_positives) / \n",
    "                                 np.sum(observed_positives))\n",
    "    \n",
    "    negative_predictive_value = (np.sum(true_negatives) / \n",
    "                                  np.sum(observed_positives))\n",
    "    \n",
    "    # Create dictionary for results, and add results\n",
    "    results = dict()\n",
    "    \n",
    "    results['observed_positive_rate'] = np.mean(observed_positives)\n",
    "    results['observed_negative_rate'] = np.mean(observed_negatives)\n",
    "    results['predicted_positive_rate'] = np.mean(predicted_positives)\n",
    "    results['predicted_negative_rate'] = np.mean(predicted_negatives)\n",
    "    results['accuracy'] = accuracy\n",
    "    results['precision'] = precision\n",
    "    results['recall'] = recall\n",
    "    results['f1'] = f1\n",
    "    results['sensitivity'] = sensitivity\n",
    "    results['specificity'] = specificity\n",
    "    results['positive_likelihood'] = positive_likelihood\n",
    "    results['negative_likelihood'] = negative_likelihood\n",
    "    results['false_positive_rate'] = false_positive_rate\n",
    "    results['false_negative_rate'] = false_negative_rate\n",
    "    results['true_positive_rate'] = true_positive_rate\n",
    "    results['true_negative_rate'] = true_negative_rate\n",
    "    results['positive_predictive_value'] = positive_predictive_value\n",
    "    results['negative_predictive_value'] = negative_predictive_value\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide into X (features) and y (labels)\n",
    "\n",
    "We will separate out our features (the data we use to make a prediction) from our label (what we are truing to predict).\n",
    "By convention our features are called `X` (usually upper case to denote multiple features), and the label (survive or not) `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Survived',axis=1) # X = all 'data' except the 'survived' column\n",
    "y = data['Survived'] # y = 'survived' column from 'data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess accuracy, precision, recall and f1 at different model classification thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run our model with probability cut-off levels\n",
    "\n",
    "We will use stratified k-fold verification to assess the model performance. If you are not familiar with this please see:\n",
    "\n",
    "https://github.com/MichaelAllen1966/1804_python_healthcare/blob/master/titanic/03_k_fold.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create NumPy arrays of X and y (required for k-fold)\n",
    "X_np = X.values\n",
    "y_np = y.values\n",
    "\n",
    "# Set up k-fold training/test splits\n",
    "number_of_splits = 10\n",
    "skf = StratifiedKFold(n_splits = number_of_splits)\n",
    "skf.get_n_splits(X_np, y_np)\n",
    "\n",
    "# Set up thresholds\n",
    "thresholds = np.arange(0, 1.01, 0.2)\n",
    "\n",
    "# Create arrays for overall results (rows=threshold, columns=k fold replicate)\n",
    "results_accuracy = np.zeros((len(thresholds),number_of_splits))\n",
    "results_precision = np.zeros((len(thresholds),number_of_splits))\n",
    "results_recall = np.zeros((len(thresholds),number_of_splits))\n",
    "results_f1 = np.zeros((len(thresholds),number_of_splits))\n",
    "results_predicted_positive_rate = np.zeros((len(thresholds),number_of_splits))\n",
    "\n",
    "# Loop through the k-fold splits\n",
    "loop_index = 0\n",
    "for train_index, test_index in skf.split(X_np, y_np):\n",
    "    \n",
    "    # Create lists for k-fold results\n",
    "    threshold_accuracy = []\n",
    "    threshold_precision = []\n",
    "    threshold_recall = []\n",
    "    threshold_f1 = []\n",
    "    threshold_predicted_positive_rate = []\n",
    "\n",
    "    # Get X and Y train/test\n",
    "    X_train, X_test = X_np[train_index], X_np[test_index]\n",
    "    y_train, y_test = y_np[train_index], y_np[test_index]\n",
    "\n",
    "    # Get X and Y train/test\n",
    "    X_train_std, X_test_std = standardise_data(X_train, X_test)\n",
    "\n",
    "    # Set up and fit model\n",
    "    model = LogisticRegression(solver='lbfgs')\n",
    "    model.fit(X_train_std,y_train)\n",
    "    \n",
    "    # Get probability of non-survive and survive\n",
    "    probabilities = model.predict_proba(X_test_std)\n",
    "    # Take just the survival probabilities (column 1)\n",
    "    probability_survival = probabilities[:,1]\n",
    "    \n",
    "    # Loop through increments in probability of survival\n",
    "    for cutoff in thresholds: #  loop 0 --> 1 on steps of 0.1\n",
    "        # Get whether passengers survive using cutoff\n",
    "        predicted_survived = probability_survival >= cutoff\n",
    "        # Call accuracy measures function\n",
    "        accuracy = calculate_accuracy(y_test, predicted_survived)\n",
    "        # Add accuracy scores to lists\n",
    "        threshold_accuracy.append(accuracy['accuracy'])\n",
    "        threshold_precision.append(accuracy['precision'])\n",
    "        threshold_recall.append(accuracy['recall'])\n",
    "        threshold_f1.append(accuracy['f1'])\n",
    "        threshold_predicted_positive_rate.append(accuracy['predicted_positive_rate'])\n",
    "    \n",
    "    # Add results to results arrays\n",
    "    results_accuracy[:,loop_index] = threshold_accuracy\n",
    "    results_precision[:, loop_index] = threshold_precision\n",
    "    results_recall[:, loop_index] = threshold_recall\n",
    "    results_f1[:, loop_index] = threshold_f1\n",
    "    results_predicted_positive_rate[:, loop_index] = threshold_predicted_positive_rate\n",
    "    \n",
    "    # Increment loop index\n",
    "    loop_index += 1\n",
    "    \n",
    "\n",
    "# Transfer results to dataframe\n",
    "results = pd.DataFrame(thresholds, columns=['thresholds'])\n",
    "results['accuracy'] = results_accuracy.mean(axis=1)\n",
    "results['precision'] = results_precision.mean(axis=1)\n",
    "results['recall'] = results_recall.mean(axis=1)\n",
    "results['f1'] = results_f1.mean(axis=1)\n",
    "results['predicted_positive_rate'] = results_predicted_positive_rate.mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "chart_x = results['thresholds']\n",
    "\n",
    "plt.plot(chart_x, results['accuracy'],\n",
    "         linestyle = '-',\n",
    "         label = 'Accuracy')\n",
    "\n",
    "plt.plot(chart_x, results['precision'],\n",
    "         linestyle = '--',\n",
    "         label = 'Precision')\n",
    "\n",
    "plt.plot(chart_x, results['recall'],\n",
    "         linestyle = '-.',\n",
    "         label = 'Recall')\n",
    "\n",
    "plt.plot(chart_x, results['f1'],\n",
    "         linestyle = ':',\n",
    "         label = 'F1')\n",
    "\n",
    "plt.plot(chart_x, results['predicted_positive_rate'],\n",
    "         linestyle = '-',\n",
    "         label = 'Predicted positive rate')\n",
    "\n",
    "actual_positive_rate = np.repeat(y.mean(), len(chart_x))\n",
    "\n",
    "plt.plot(chart_x, actual_positive_rate,\n",
    "         linestyle = '--',\n",
    "         color='k',\n",
    "         label = 'Actual positive rate')\n",
    "\n",
    "\n",
    "plt.xlabel('Probability threshold')\n",
    "plt.ylabel('Score')\n",
    "plt.xlim(-0.02, 1.02)\n",
    "plt.ylim(-0.02, 1.02)\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations\n",
    "\n",
    "* Accuracy is maximised with a probability threshold of 0.5\n",
    "* When the threshold is set at 0.5 (the default threshold for classification) minority class ('survived') is under-predicted.\n",
    "* A threshold of 0.4 balances precision and recall and correctly estimates the proportion of passengers who survive.\n",
    "* There is a marginal reduction in overall accuracy in order to balance accuracy of the classes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
