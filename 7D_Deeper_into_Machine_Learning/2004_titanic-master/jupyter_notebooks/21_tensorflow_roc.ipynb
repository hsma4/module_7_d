{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Titanic survival - TensorFlow Receiver Operator Characteristic (ROC) curve and balancing of model classification\n",
    "\n",
    "In this model we extend our previous TensorFlow model to build a Receiver Operator Characteristic (ROC) curve, as described at:\n",
    "\n",
    "https://github.com/MichaelAllen1966/1804_python_healthcare/blob/master/titanic/06_roc_sensitivity_specificity.ipynb\n",
    "\n",
    "The previous TensorFlow model (using the API method) is described at:\n",
    "\n",
    "https://github.com/MichaelAllen1966/1804_python_healthcare/blob/master/titanic/20b_tensorflow_api.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn warnings off to keep notebook tidy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "# TensorFlow api model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.losses import binary_crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data if not previously downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_required = True\n",
    "\n",
    "if download_required:\n",
    "    \n",
    "    # Download processed data:\n",
    "    address = 'https://raw.githubusercontent.com/MichaelAllen1966/' + \\\n",
    "                '1804_python_healthcare/master/titanic/data/processed_data.csv'\n",
    "    \n",
    "    data = pd.read_csv(address)\n",
    "\n",
    "    # Create a data subfolder if one does not already exist\n",
    "    import os\n",
    "    data_directory ='./data/'\n",
    "    if not os.path.exists(data_directory):\n",
    "        os.makedirs(data_directory)\n",
    "\n",
    "    # Save data\n",
    "    data.to_csv(data_directory + 'processed_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define function to calculate accuracy measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(observed, predicted):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculates a range of accuracy scores from observed and predicted classes.\n",
    "    \n",
    "    Takes two list or NumPy arrays (observed class values, and predicted class \n",
    "    values), and returns a dictionary of results.\n",
    "    \n",
    "     1) observed positive rate: proportion of observed cases that are +ve\n",
    "     2) Predicted positive rate: proportion of predicted cases that are +ve\n",
    "     3) observed negative rate: proportion of observed cases that are -ve\n",
    "     4) Predicted negative rate: proportion of predicted cases that are -ve  \n",
    "     5) accuracy: proportion of predicted results that are correct    \n",
    "     6) precision: proportion of predicted +ve that are correct\n",
    "     7) recall: proportion of true +ve correctly identified\n",
    "     8) f1: harmonic mean of precision and recall\n",
    "     9) sensitivity: Same as recall\n",
    "    10) specificity: Proportion of true -ve identified:        \n",
    "    11) positive likelihood: increased probability of true +ve if test +ve\n",
    "    12) negative likelihood: reduced probability of true +ve if test -ve\n",
    "    13) false positive rate: proportion of false +ves in true -ve patients\n",
    "    14) false negative rate: proportion of false -ves in true +ve patients\n",
    "    15) true positive rate: Same as recall\n",
    "    16) true negative rate\n",
    "    17) positive predictive value: chance of true +ve if test +ve\n",
    "    18) negative predictive value: chance of true -ve if test -ve\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Converts list to NumPy arrays\n",
    "    if type(observed) == list:\n",
    "        observed = np.array(observed)\n",
    "    if type(predicted) == list:\n",
    "        predicted = np.array(predicted)\n",
    "    \n",
    "    # Calculate accuracy scores\n",
    "    observed_positives = observed == 1\n",
    "    observed_negatives = observed == 0\n",
    "    predicted_positives = predicted == 1\n",
    "    predicted_negatives = predicted == 0\n",
    "    \n",
    "    true_positives = (predicted_positives == 1) & (observed_positives == 1)\n",
    "    \n",
    "    false_positives = (predicted_positives == 1) & (observed_positives == 0)\n",
    "    \n",
    "    true_negatives = (predicted_negatives == 1) & (observed_negatives == 1)\n",
    "    \n",
    "    accuracy = np.mean(predicted == observed)\n",
    "    \n",
    "    precision = (np.sum(true_positives) /\n",
    "                 (np.sum(true_positives) + np.sum(false_positives)))\n",
    "        \n",
    "    recall = np.sum(true_positives) / np.sum(observed_positives)\n",
    "    \n",
    "    sensitivity = recall\n",
    "    \n",
    "    f1 = 2 * ((precision * recall) / (precision + recall))\n",
    "    \n",
    "    specificity = np.sum(true_negatives) / np.sum(observed_negatives)\n",
    "    \n",
    "    positive_likelihood = sensitivity / (1 - specificity)\n",
    "    \n",
    "    negative_likelihood = (1 - sensitivity) / specificity\n",
    "    \n",
    "    false_positive_rate = 1 - specificity\n",
    "    \n",
    "    false_negative_rate = 1 - sensitivity\n",
    "    \n",
    "    true_positive_rate = sensitivity\n",
    "    \n",
    "    true_negative_rate = specificity\n",
    "    \n",
    "    positive_predictive_value = (np.sum(true_positives) / \n",
    "                                 np.sum(observed_positives))\n",
    "    \n",
    "    negative_predictive_value = (np.sum(true_negatives) / \n",
    "                                  np.sum(observed_positives))\n",
    "    \n",
    "    # Create dictionary for results, and add results\n",
    "    results = dict()\n",
    "    \n",
    "    results['observed_positive_rate'] = np.mean(observed_positives)\n",
    "    results['observed_negative_rate'] = np.mean(observed_negatives)\n",
    "    results['predicted_positive_rate'] = np.mean(predicted_positives)\n",
    "    results['predicted_negative_rate'] = np.mean(predicted_negatives)\n",
    "    results['accuracy'] = accuracy\n",
    "    results['precision'] = precision\n",
    "    results['recall'] = recall\n",
    "    results['f1'] = f1\n",
    "    results['sensitivity'] = sensitivity\n",
    "    results['specificity'] = specificity\n",
    "    results['positive_likelihood'] = positive_likelihood\n",
    "    results['negative_likelihood'] = negative_likelihood\n",
    "    results['false_positive_rate'] = false_positive_rate\n",
    "    results['false_negative_rate'] = false_negative_rate\n",
    "    results['true_positive_rate'] = true_positive_rate\n",
    "    results['true_negative_rate'] = true_negative_rate\n",
    "    results['positive_predictive_value'] = positive_predictive_value\n",
    "    results['negative_predictive_value'] = negative_predictive_value\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define function to scale data\n",
    "\n",
    "In neural networks it is common to to scale input data 0-1 rather than use standardisation (subtracting mean and dividing by standard deviation) of each feature)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(X_train, X_test):\n",
    "    \"\"\"Scale data 0-1 based on min and max in training set\"\"\"\n",
    "    \n",
    "    # Initialise a new scaling object for normalising input data\n",
    "    sc = MinMaxScaler()\n",
    "\n",
    "    # Set up the scaler just on the training set\n",
    "    sc.fit(X_train)\n",
    "\n",
    "    # Apply the scaler to the training and test sets\n",
    "    train_sc = sc.transform(X_train)\n",
    "    test_sc = sc.transform(X_test)\n",
    "    \n",
    "    return train_sc, test_sc\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/processed_data.csv')\n",
    "# Make all data 'float' type\n",
    "data = data.astype(float)\n",
    "data.drop('PassengerId', inplace=True, axis=1)\n",
    "X = data.drop('Survived',axis=1) # X = all 'data' except the 'survived' column\n",
    "y = data['Survived'] # y = 'survived' column from 'data'\n",
    "# Convert to NumPy as required for k-fold splits\n",
    "X_np = X.values\n",
    "y_np = y.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use the api-based method to set up a TensorFlow neural network. This method allows us to more flexibly define the inputs for each layer, rather than assuming there is a simple sequence as with the `Sequential` method.\n",
    "\n",
    "We will put construction of the neural net into a separate function.\n",
    "\n",
    "The neural net is a relatively simple network. The inputs are connected to two hidden layers (of 240 and 50 nodes) before being connected to two output nodes corresponding to each class (died and survived). It also contains some useful additions (batch normalisation and dropout) as described below.\n",
    "\n",
    "The layers of the network are:\n",
    "\n",
    "1) An input layer (which *does* need to be defined) \n",
    "\n",
    "2) A fully-connected (dense) layer.This is defined by the number of inputs (the number of input features) and the number of outputs. We will expand out feature data set up to 240 outputs. The output of the layer uses ReLU  (rectified linear unit) activation. ReLU activation is most common for the inner layers of a neural network. Negative input values are set to zero. Positive input values are left unchanged.\n",
    "\n",
    "3) A batch normalisation layer. This is not usually used for small models, but can increase the speed of training for larger models. It is added here as an example of how to include it (in large models all dense layers would be followed by a batch normalisation layer). The layer definition includes the number of inputs to normalise.\n",
    "\n",
    "4) A dropout layer. This layer randomly sets outputs from the preceding layer to zero during training (a different set of outputs is zeroed for each training iteration). This helps prevent over-fitting of the model to the training data. Typically between 0.1 and 0.3 outputs are set to zero (`p=0.1` means 10% of outputs are set to zero).\n",
    "\n",
    "5) A second fully connected layer which reduces the network down to 50 nodes. This again uses ReLU activation and is followed by batch normalisation, and dropout layers.\n",
    "\n",
    "7) A final fully connected linear layer of one nodes (more nodes could be used for more classes, in which case use `softmax` activation and `categorical_crossentropy` in the loss function).\n",
    "\n",
    "The output of the net is the probability of surviving (usually a probability of >= 0.5 will be classes as 'survived')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_net(number_features, learning_rate=0.003):\n",
    "    \n",
    "    # Clear Tensorflow\n",
    "    K.clear_session()\n",
    "       \n",
    "    inputs = layers.Input(shape=number_features)\n",
    "    dense_1 = layers.Dense(240, activation='relu')(inputs)\n",
    "    norm_1 = layers.BatchNormalization()(dense_1)\n",
    "    dropout_1 = layers.Dropout(0.25)(norm_1)\n",
    "    dense_2 = layers.Dense(50, activation='relu')(dropout_1)\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(dense_2)\n",
    "    \n",
    "    net = Model(inputs, outputs)\n",
    "    \n",
    "    # Compiling model\n",
    "    opt = Adam(lr=learning_rate)\n",
    "    \n",
    "    net.compile(loss='binary_crossentropy', \n",
    "                optimizer=opt, \n",
    "                metrics=['accuracy'])\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the model with k-fold validation and ROC calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up k-fold training/test splits\n",
    "number_of_splits = 5\n",
    "skf = StratifiedKFold(n_splits = number_of_splits)\n",
    "skf.get_n_splits(X_np, y_np)\n",
    "\n",
    "# Set up thresholds\n",
    "thresholds = np.arange(0, 1.01, 0.01)\n",
    "\n",
    "# Create arrays for overall results (rows=threshold, columns=k fold replicate)\n",
    "results_accuracy = np.zeros((len(thresholds),number_of_splits))\n",
    "results_precision = np.zeros((len(thresholds),number_of_splits))\n",
    "results_recall = np.zeros((len(thresholds),number_of_splits))\n",
    "results_f1 = np.zeros((len(thresholds),number_of_splits))\n",
    "results_predicted_positive_rate = np.zeros((len(thresholds),number_of_splits))\n",
    "results_observed_positive_rate = np.zeros((len(thresholds),number_of_splits))\n",
    "results_true_positive_rate = np.zeros((len(thresholds),number_of_splits))\n",
    "results_false_positive_rate = np.zeros((len(thresholds),number_of_splits))\n",
    "results_auc = []\n",
    "\n",
    "# Loop through the k-fold splits\n",
    "loop_index = 0\n",
    "for train_index, test_index in skf.split(X_np, y_np):\n",
    "    \n",
    "    # Create lists for k-fold results\n",
    "    threshold_accuracy = []\n",
    "    threshold_precision = []\n",
    "    threshold_recall = []\n",
    "    threshold_f1 = []\n",
    "    threshold_predicted_positive_rate = []\n",
    "    threshold_observed_positive_rate = []\n",
    "    threshold_true_positive_rate = []\n",
    "    threshold_false_positive_rate = []\n",
    "\n",
    "    # Get X and Y train/test\n",
    "    X_train, X_test = X_np[train_index], X_np[test_index]\n",
    "    y_train, y_test = y_np[train_index], y_np[test_index]\n",
    "\n",
    "    # Set up and fit model\n",
    "    X_train_sc, X_test_sc = scale_data(X_train, X_test)\n",
    "    \n",
    "    # Define network\n",
    "    number_features = X_train_sc.shape[1]\n",
    "    model = make_net(number_features)\n",
    "    \n",
    "    ### Train model\n",
    "    model.fit(X_train_sc,\n",
    "             y_train,\n",
    "             epochs=150,\n",
    "             batch_size=512,\n",
    "             verbose=0)\n",
    "\n",
    "    \n",
    "    # Get probability of non-survive and survive\n",
    "    probability_survival = model.predict(X_test_sc)\n",
    "    probability_survival = probability_survival.flatten()\n",
    "    \n",
    "    # Loop through increments in probability of survival\n",
    "    for cutoff in thresholds: #  loop 0 --> 1 on steps of 0.1\n",
    "        # Get whether passengers survive using cutoff\n",
    "        predicted_survived = probability_survival >= cutoff\n",
    "        # Call accuracy measures function\n",
    "        accuracy = calculate_accuracy(y_test, predicted_survived)\n",
    "        # Add accuracy scores to lists\n",
    "        threshold_accuracy.append(accuracy['accuracy'])\n",
    "        threshold_precision.append(accuracy['precision'])\n",
    "        threshold_recall.append(accuracy['recall'])\n",
    "        threshold_f1.append(accuracy['f1'])\n",
    "        threshold_predicted_positive_rate.append(\n",
    "                accuracy['predicted_positive_rate'])\n",
    "        threshold_observed_positive_rate.append(\n",
    "                accuracy['observed_positive_rate'])\n",
    "        threshold_true_positive_rate.append(accuracy['true_positive_rate'])\n",
    "        threshold_false_positive_rate.append(accuracy['false_positive_rate'])\n",
    "    \n",
    "    # Add results to results arrays\n",
    "    results_accuracy[:,loop_index] = threshold_accuracy\n",
    "    results_precision[:, loop_index] = threshold_precision\n",
    "    results_recall[:, loop_index] = threshold_recall\n",
    "    results_f1[:, loop_index] = threshold_f1\n",
    "    results_predicted_positive_rate[:, loop_index] = \\\n",
    "        threshold_predicted_positive_rate\n",
    "    results_observed_positive_rate[:, loop_index] = \\\n",
    "        threshold_observed_positive_rate\n",
    "    results_true_positive_rate[:, loop_index] = threshold_true_positive_rate\n",
    "    results_false_positive_rate[:, loop_index] = threshold_false_positive_rate\n",
    "    \n",
    "    # Calculate ROC AUC\n",
    "    roc_auc = auc(threshold_false_positive_rate, threshold_true_positive_rate)\n",
    "    results_auc.append(roc_auc)\n",
    "    \n",
    "    # Increment loop index\n",
    "    loop_index += 1\n",
    "    \n",
    "\n",
    "# Transfer summary results to dataframe\n",
    "results = pd.DataFrame(thresholds, columns=['thresholds'])\n",
    "results['accuracy'] = results_accuracy.mean(axis=1)\n",
    "results['precision'] = results_precision.mean(axis=1)\n",
    "results['recall'] = results_recall.mean(axis=1)\n",
    "results['f1'] = results_f1.mean(axis=1)\n",
    "results['predicted_positive_rate'] = \\\n",
    "    results_predicted_positive_rate.mean(axis=1)\n",
    "results['observed_positive_rate'] = \\\n",
    "    results_observed_positive_rate.mean(axis=1)\n",
    "results['true_positive_rate'] = results_true_positive_rate.mean(axis=1)\n",
    "results['false_positive_rate'] = results_false_positive_rate.mean(axis=1)\n",
    "results['roc_auc'] = np.mean(results_auc)\n",
    "\n",
    "mean_auc = np.mean(results_auc)\n",
    "mean_auc = np.round(mean_auc, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "for i in range(number_of_splits):\n",
    "    plt.plot(results_false_positive_rate[:, i],\n",
    "             results_true_positive_rate[:, i],\n",
    "             color='black',\n",
    "             linestyle=':',\n",
    "             linewidth=1)\n",
    "plt.plot(results_false_positive_rate.mean(axis=1),\n",
    "         results_true_positive_rate.mean(axis=1),\n",
    "         color='red',\n",
    "         linestyle='-',\n",
    "         linewidth=2)\n",
    "plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "plt.title('Receiver Operator Characteristic (ROC) Curve')\n",
    "plt.grid(True)\n",
    "props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "text = \"Mean AUC = \" + str(mean_auc)\n",
    "plt.text(0.65, 0.08, text, bbox=props)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot effects of changing classification probability threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_x = results['thresholds']\n",
    "\n",
    "plt.plot(chart_x, results['accuracy'],\n",
    "         linestyle = '-',\n",
    "         label = 'Accuracy')\n",
    "\n",
    "plt.plot(chart_x, results['precision'],\n",
    "         linestyle = '--',\n",
    "         label = 'Precision')\n",
    "\n",
    "plt.plot(chart_x, results['recall'],\n",
    "         linestyle = '-.',\n",
    "         label = 'Recall')\n",
    "\n",
    "plt.plot(chart_x, results['f1'],\n",
    "         linestyle = ':',\n",
    "         label = 'F1')\n",
    "\n",
    "plt.plot(chart_x, results['predicted_positive_rate'],\n",
    "         linestyle = '-',\n",
    "         label = 'Predicted positive rate')\n",
    "\n",
    "plt.plot(chart_x, results['observed_positive_rate'],\n",
    "         linestyle = '--',\n",
    "         color='k',\n",
    "         label = 'Observed positive rate')\n",
    "\n",
    "\n",
    "plt.xlabel('Probability cutoff for classifcation')\n",
    "plt.ylabel('Score')\n",
    "plt.ylim(-0.02, 1.02)\n",
    "plt.legend(loc='lower left', ncol=2)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations\n",
    "\n",
    "* Using the default values for probability cut-off, the TensorFlow model under-predicts the proportion of passengers who survive (the minority class).\n",
    "* Without rebalancing of classes (under-sampling of the majority class, or over-sampling of the minority class) the model may be rebalanced by adjusting the probability threshold for classification (at the cost of a small reduction in overall accuracy)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
