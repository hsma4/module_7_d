{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Titanic survival - Monte Carlo Dropout\n",
    "\n",
    "In 2016, Gal and Ghahramani introduced a simple but powerful technique for enhancing accuracy of neural networks, and providing a measure of uncertainty, without increasing training overhead.\n",
    "\n",
    "Usually 'dropout', the random removal of neurones in a network, is used only in training (to reduce over-fitting to the training data). In Monte Carlo Dropout, dropout layers are used during evaluation as well. We obtain multiple estimates of classification probability, each using a different random selection of eliminated neurones. We can then take the mean across these models, and also look at the spread of probabilities in order to get a measure of model uncertainty.\n",
    "\n",
    "The paper may be found at: https://arxiv.org/abs/1506.02142\n",
    "\n",
    "This method does not require any change to the training of the network, and the implemtation therefasfter is simple!\n",
    "\n",
    "We will use a simple model here, and just use a single training/test split so that we focus on the Monte Carlo Dropout method. In practice, k-fold validation should be used.\n",
    "\n",
    "(The original paper on the use of droput is: Srivastava N, Hinton G, Krizhevsky A, et al. Dropout: A Simple Way to Prevent Neural Networks from Overfitting. Journal of Machine Learning Research 2014;15:1929â€“58. https://jmlr.org/papers/v15/srivastava14a.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn warnings off to keep notebook tidy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# sklearn for pre-processing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# TensorFlow api model\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.losses import binary_crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data if not previously downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_required = True\n",
    "\n",
    "if download_required:\n",
    "    \n",
    "    # Download processed data:\n",
    "    address = 'https://raw.githubusercontent.com/MichaelAllen1966/' + \\\n",
    "                '1804_python_healthcare/master/titanic/data/processed_data.csv'\n",
    "    \n",
    "    data = pd.read_csv(address)\n",
    "\n",
    "    # Create a data subfolder if one does not already exist\n",
    "    import os\n",
    "    data_directory ='./data/'\n",
    "    if not os.path.exists(data_directory):\n",
    "        os.makedirs(data_directory)\n",
    "\n",
    "    # Save data\n",
    "    data.to_csv(data_directory + 'processed_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define function to scale data\n",
    "\n",
    "In neural networks it is common to to scale input data 0-1 rather than use standardisation (subtracting mean and dividing by standard deviation) of each feature)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(X_train, X_test):\n",
    "    \"\"\"Scale data 0-1 based on min and max in training set\"\"\"\n",
    "    \n",
    "    # Initialise a new scaling object for normalising input data\n",
    "    sc = MinMaxScaler()\n",
    "\n",
    "    # Set up the scaler just on the training set\n",
    "    sc.fit(X_train)\n",
    "\n",
    "    # Apply the scaler to the training and test sets\n",
    "    train_sc = sc.transform(X_train)\n",
    "    test_sc = sc.transform(X_test)\n",
    "    \n",
    "    return train_sc, test_sc\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/processed_data.csv')\n",
    "# Make all data 'float' type\n",
    "data = data.astype(float)\n",
    "data.drop('PassengerId', inplace=True, axis=1)\n",
    "X = data.drop('Survived',axis=1) # X = all 'data' except the 'survived' column\n",
    "y = data['Survived'] # y = 'survived' column from 'data'\n",
    "# Convert to NumPy as required for k-fold splits\n",
    "X_np = X.values\n",
    "y_np = y.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_net(number_features, learning_rate=0.003):\n",
    "    \n",
    "    # Clear Tensorflow\n",
    "    K.clear_session()\n",
    "    \n",
    "    # Define layers\n",
    "    inputs = layers.Input(shape=number_features)\n",
    "    dropout_0 = layers.Dropout(0.2)(inputs)\n",
    "    \n",
    "    dense_1 = layers.Dense(240, activation='relu')(dropout_0)\n",
    "    dropout_1 = layers.Dropout(0.2)(dense_1)\n",
    "    \n",
    "    dense_2 = layers.Dense(50, activation='relu')(dropout_1)\n",
    "    dropout_2 = layers.Dropout(0.2)(dense_2)\n",
    "  \n",
    "    outputs = layers.Dense(1, activation='sigmoid')(dropout_2)\n",
    "    \n",
    "    \n",
    "    net = Model(inputs, outputs)\n",
    "    \n",
    "    # Compiling model\n",
    "    opt = Adam(lr=learning_rate)\n",
    "    net.compile(loss='binary_crossentropy',\n",
    "    optimizer=opt,\n",
    "    metrics=['accuracy'])\n",
    "    return net\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show summary of the model structure\n",
    "\n",
    "Here we will create a model with 10 input features and show the structure of the model as  atable and as a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_net(10)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the plot of the model shows how the imput layer is connected to both the first dense layer and the concatenation layer prior to the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If necessary conda install pydot and graphviz\n",
    "keras.utils.plot_model(model, \"titanic_tf_model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_np, y_np, test_size = 0.25)\n",
    "\n",
    "# Scale data\n",
    "X_train_sc, X_test_sc = scale_data(X_train, X_test)\n",
    "\n",
    "# Define network\n",
    "number_features = X_train_sc.shape[1]\n",
    "model = make_net(number_features)\n",
    "\n",
    "# Train model\n",
    "history = model.fit(X_train_sc,\n",
    "                    y_train,\n",
    "                    epochs=100,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(X_test_sc, y_test),\n",
    "                    verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`history` is a dictionary containing data collected during training. Let's take a look at the keys in this dictionary (these are the metrics monitored during training):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot training history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "acc_values = history_dict['accuracy']\n",
    "val_acc_values = history_dict['val_accuracy']\n",
    "epochs = range(1, len(acc_values) + 1)\n",
    "\n",
    "with plt.xkcd():\n",
    "    plt.plot(epochs, acc_values, 'bo', label='Training acc')\n",
    "    plt.plot(epochs, val_acc_values, 'b', label='Test accuracy')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte Carlo Dropout\n",
    "\n",
    "In Monte Carlo Dropout we maintain use of the dropout layers during evaluation (they are usually only used in training). Here we get estimates of survival probability from 30 different dropout configurations of the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get multiple probability estimates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_estimates = 100\n",
    "y_probas_dropout = np.stack(\n",
    "    [model(X_test_sc, training=True) for sample in range (num_estimates)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get mean probabilities, and classify those with mean >= 0.5 as surviving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba_dropout = y_probas_dropout.mean(axis=0)\n",
    "y_predict_dropout = y_proba_dropout >= 0.5\n",
    "y_predict_dropout = y_predict_dropout.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get normal predictions (without dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get normal predictions (without dropout) \n",
    "y_proba = model.predict(X_test_sc)\n",
    "y_predict = y_proba >= 0.5\n",
    "y_predict = y_predict.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show accuracy scores (we are doing a single test set here; in practice k-fold validation should be used)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = np.mean(y_predict == y_test)\n",
    "accuracy_dropout = np.mean(y_predict_dropout == y_test)\n",
    "print (f'Accuracy without dropout {accuracy:0.2f}')\n",
    "print (f'Accuracy with dropout {accuracy_dropout:0.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot comparisons of dropout method and standard method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_error = y_probas_dropout.std(axis=0)/np.sqrt(num_estimates)\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ax.errorbar(y_proba, y_proba_dropout, yerr = y_error, fmt='o')\n",
    "ax.grid()\n",
    "ax.set_xlabel('Probability survival without dropout')\n",
    "ax.set_ylabel('Probability survival with dropout')\n",
    "ax.set_xlim(0,1)\n",
    "ax.set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show variation in prediction (across the dropout replicates) depending on probability of survival.\n",
    "\n",
    "Here we will use standard error of the mean as one measure of uncertainty. Note how uncertainty is not even - there is less variation in prediction of those with high probability of survival compared with those with lower probability of survival."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.xkcd():\n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "    ax.scatter(y_proba, y_error)\n",
    "    ax.set_xlabel('Probability survival')\n",
    "    ax.set_ylabel('Standard Error of Survival Probability')\n",
    "    ax.set_xlim(0,1)\n",
    "    ax.set_ylim(0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "If you wish to use other types oflayer that behave differently between training and test (such as batch normalization) then you should not use the method described above where the whole net is run in training mode. Rather you define a custome dropout layer class that is always set to behave as if it is in training mode. Tis is then used as a simple drop-in replacement for normal Dropout layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCDropout(keras.layers.Dropout):\n",
    "    def call(self, inputs):\n",
    "        return super().call(inputs, training=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
