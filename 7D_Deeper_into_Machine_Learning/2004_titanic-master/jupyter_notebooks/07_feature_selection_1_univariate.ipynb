{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Titanic survival - feature selection 1 (univariate statistical selection)\n",
    "\n",
    "Reducing the number of features we use can have three benefits:\n",
    "\n",
    "* Simplifies model explanation\n",
    "* Model fit may be improved by the removal of features that add no value\n",
    "* Model will be faster to fit\n",
    "\n",
    "In this notebook we will use a simple statistical method for selecting features called univariate feature selection. We will examine the correlation between each feature and the target label value. This is called univariate statistics because we examine each feature independently. \n",
    "\n",
    "Two key advantages of this method are:\n",
    "\n",
    "* It is simple\n",
    "* It is fast\n",
    "\n",
    "Two key disadvantage of this method are:\n",
    "\n",
    "* It may miss features which have little effect alone, but which are influential when combined\n",
    "* It may include features which are highly correlated which could be reduced to choosing just one of the highly correlated features.\n",
    "\n",
    "The machine learning model we will use to test the feature selection is as previously described:\n",
    "\n",
    "https://github.com/MichaelAllen1966/1804_python_healthcare/blob/master/titanic/02_logistic_regression.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will go through the following steps:\n",
    "\n",
    "* Download and save pre-processed data\n",
    "* Split data into features (X) and label (y)\n",
    "* Calculate the correlation of each feature with the target label value\n",
    "* Sort by correlation (ignoring the +ve/-ve sign)\n",
    "* Test the features in our logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hide warnings (to keep notebook tidy; do not usually do this)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load modules\n",
    "\n",
    "A standard Anaconda install of Python (https://www.anaconda.com/distribution/) contains all the necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Import machine learning methods\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "The section below downloads pre-processed data, and saves it to a subfolder (from where this code is run).\n",
    "If data has already been downloaded that cell may be skipped.\n",
    "\n",
    "Code that was used to pre-process the data ready for machine learning may be found at:\n",
    "https://github.com/MichaelAllen1966/1804_python_healthcare/blob/master/titanic/01_preprocessing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_required = True\n",
    "\n",
    "if download_required:\n",
    "    \n",
    "    # Download processed data:\n",
    "    address = 'https://raw.githubusercontent.com/MichaelAllen1966/' + \\\n",
    "                '1804_python_healthcare/master/titanic/data/processed_data.csv'\n",
    "    \n",
    "    data = pd.read_csv(address)\n",
    "\n",
    "    # Create a data subfolder if one does not already exist\n",
    "    import os\n",
    "    data_directory ='./data/'\n",
    "    if not os.path.exists(data_directory):\n",
    "        os.makedirs(data_directory)\n",
    "\n",
    "    # Save data\n",
    "    data.to_csv(data_directory + 'processed_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/processed_data.csv')\n",
    "# Make all data 'float' type\n",
    "data = data.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first column is a passenger index number. We will remove this, as this is not part of the original Titanic passenger data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Passengerid (axis=1 indicates we are removing a column rather than a row)\n",
    "# We drop passenger ID as it is not original data\n",
    "\n",
    "data.drop('PassengerId', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide into X (features) and y (labels)\n",
    "\n",
    "We will separate out our features (the data we use to make a prediction) from our label (what we are truing to predict).\n",
    "By convention our features are called `X` (usually upper case to denote multiple features), and the label (survive or not) `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Survived',axis=1) # X = all 'data' except the 'survived' column\n",
    "y = data['Survived'] # y = 'survived' column from 'data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate correlation coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.stats import pearsonr\n",
    "features = list(X)\n",
    "correlation = []\n",
    "significance = []\n",
    "for feature in features:\n",
    "    correl = pearsonr(X[feature].values, y.values)\n",
    "    correlation.append(correl[0])\n",
    "    significance.append(correl[1])\n",
    "df = pd.DataFrame()\n",
    "df['feature'] = features\n",
    "df['correlation'] = correlation\n",
    "df['abs_correlation'] = np.abs(correlation)\n",
    "df['significance'] = significance\n",
    "df['significant'] = df['significance'] < 0.05 # Label those P<0.01\n",
    "df.sort_values(by='abs_correlation', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show features in order of correlation with survival."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get ordered feature list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_features = list(df['feature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing our selected features\n",
    "\n",
    "After statistical selection we may simply choose the top *k* features, or we may choose those labelled as significant (P<0.05). \n",
    "\n",
    "Here we will inclemently add features to the list of features to use (chosen in order of their correlation coefficients), and see the effect on model accuracy and ROC AUC as measured by k-fold stratification.\n",
    "\n",
    "If you are not familiar with k-fold stratification, have a look at:\n",
    "\n",
    "https://github.com/MichaelAllen1966/1804_python_healthcare/blob/master/titanic/03_k_fold.ipynb\n",
    "\n",
    "If you are not familiar with ROC AUC, have a look at:\n",
    "\n",
    "https://github.com/MichaelAllen1966/1804_python_healthcare/blob/master/titanic/06_roc_sensitivity_specificity.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardise_data(X_train, X_test):\n",
    "    \n",
    "    # Initialise a new scaling object for normalising input data\n",
    "    sc = StandardScaler() \n",
    "\n",
    "    # Set up the scaler just on the training set\n",
    "    sc.fit(X_train)\n",
    "\n",
    "    # Apply the scaler to the training and test sets\n",
    "    train_std=sc.transform(X_train)\n",
    "    test_std=sc.transform(X_test)\n",
    "    \n",
    "    return train_std, test_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list to store accuracies\n",
    "accuracy_by_feature_number = []\n",
    "roc_auc_by_feature_number = []\n",
    "\n",
    "# Loop through feature list\n",
    "number_of_features = len(ordered_features)\n",
    "for i in range(number_of_features):\n",
    "    # print (\"{0} features of {1}\".format(i, number_of_features))\n",
    "    features_to_use = ordered_features[0:i+1]\n",
    "    X_selected = X[features_to_use]\n",
    "    \n",
    "    # Convert to NumPy (needed for k-fold method)\n",
    "    # Convert DataFrames to NumPy arrays\n",
    "    X_np = X_selected.values\n",
    "    y_np = y.values\n",
    "    \n",
    "    #%% Run k fold model\n",
    "\n",
    "    # Set up lists to hold results for each k-fold run\n",
    "    test_acc_results = []\n",
    "    test_auc_results = []\n",
    "\n",
    "    # Set up splits\n",
    "    number_of_splits = 10\n",
    "    skf = StratifiedKFold(n_splits = number_of_splits)\n",
    "    skf.get_n_splits(X_np, y)\n",
    "\n",
    "    # Loop through the k-fold splits\n",
    "    for train_index, test_index in skf.split(X_np, y_np):\n",
    "        # Get X and Y train/test\n",
    "        X_train, X_test = X_np[train_index], X_np[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # Get X and Y train/test\n",
    "        X_train_std, X_test_std = standardise_data(X_train, X_test)\n",
    "\n",
    "        # Set up and fit model\n",
    "        model = LogisticRegression(solver='lbfgs')\n",
    "        model.fit(X_train_std,y_train)\n",
    "\n",
    "        # Predict test set labels\n",
    "        y_pred_test = model.predict(X_test_std)\n",
    "        \n",
    "        # Calculate accuracy of test sets\n",
    "        accuracy_test = np.mean(y_pred_test == y_test)\n",
    "        test_acc_results.append(accuracy_test)\n",
    "        \n",
    "        # Get ROC AUC\n",
    "        probabilities = model.predict_proba(X_test_std)\n",
    "        probabilities = probabilities[:, 1] # Probability of 'survived' class\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, probabilities)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        test_auc_results.append(roc_auc)      \n",
    "        \n",
    "    # Add mean accuracy and AUC to record of accuracy by feature number\n",
    "    accuracy_by_feature_number.append(np.mean(test_acc_results))\n",
    "    roc_auc_by_feature_number.append(np.mean(test_auc_results)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_x = list(range(1, number_of_features + 1))\n",
    "\n",
    "plt.plot(chart_x, accuracy_by_feature_number,\n",
    "        label = 'Accuracy')\n",
    "\n",
    "plt.plot(chart_x, roc_auc_by_feature_number,\n",
    "        label = 'ROC AUC')\n",
    "\n",
    "plt.xlabel('Number of features')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results show that our ROC AUC* increases significantly between 1 and 2 features, and then climbs slowly up to about 20 features. Accuracy, interestingly, first declines with more features, and then climbs, to a plateau between 16 and 22 features.\n",
    "\n",
    "Taking the top 20 features is likely to give us our best model (though we could reduce features more if computational time was critical).\n",
    "\n",
    "*A reminder that ROC AUC is a measure of the balance between true positive and false positives as the threshold to classify a case as a positive is changed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
