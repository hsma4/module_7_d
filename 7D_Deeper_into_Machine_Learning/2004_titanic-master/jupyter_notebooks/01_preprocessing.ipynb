{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Titanic survival - data preprocessing\n",
    "\n",
    "Can we predict which passengers would survive the sinking of the Titanic?\n",
    "\n",
    "Original kaggle page:https://www.kaggle.com/c/titanic\n",
    "\n",
    "Subsequent machine learning notebooks using Titanic survival also provide links to load preprocessed data directly, so this notebook is not strictly needed before using other notebooks, but processing data into a useable form is often a key stage of any machine learning project, and so all practitioners will want to get to grips with common methods.\n",
    "\n",
    "This Notebook introduces the following:\n",
    "\n",
    "* Using Pandas to load and process data (though some familiarity with Pandas is assumed)\n",
    "* Looking at data types\n",
    "* Listing feature headings\n",
    "* Showing data\n",
    "* Showing a statistical summary of data\n",
    "* Filling in (imputing) missing data\n",
    "* Encoding non-numerical fields\n",
    "* Removing unwanted columns\n",
    "* Saving processed data\n",
    "\n",
    "\n",
    "The data includes.\n",
    "\n",
    "Variable  | Definition\n",
    "----------|-----------\n",
    "survival  | Survival (0 = No, 1 = Yes)\n",
    "pclass    | Ticket class\n",
    "sex       | Sex\n",
    "Age       | Age in years\n",
    "sibsp     | # of siblings / spouses aboard the Titanic\n",
    "parch     | # of parents / children aboard the Titanic\n",
    "ticket    | Ticket number\n",
    "fare      | Passenger fare\n",
    "cabin     | Cabin number\n",
    "embarked  | Port of Embarkation(C=Cherbourg, Q=Queenstown, S=Southampton)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "\n",
    "Data should be in a sub folder named data.\n",
    "\n",
    "It may be downloaded from:\n",
    "\n",
    "https://gitlab.com/michaelallen1966/1908_coding_club_kaggle_titanic/tree/master/data\n",
    "\n",
    "Usually the first thing we will do is split data in training and test (usually with randomisation first), and we hold back the test data until model building is complete. In the case of this kaggle data a separate test data set is supplied, so we do not need to hold back and of the data.\n",
    "\n",
    "We will load the kaggle data and make a copy we will work on (so we can always refer back to the original data if we wish)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_required = False\n",
    "\n",
    "if download_required:\n",
    "    \n",
    "    # Download processed data:\n",
    "    address = 'https://raw.githubusercontent.com/MichaelAllen1966/' + \\\n",
    "                '1804_python_healthcare/master/titanic/data/train.csv'\n",
    "    \n",
    "    data = pd.read_csv(address)\n",
    "\n",
    "    # Create a data subfolder if one does not already exist\n",
    "    import os\n",
    "    data_directory ='./data/'\n",
    "    if not os.path.exists(data_directory):\n",
    "        os.makedirs(data_directory)\n",
    "\n",
    "    # Save data\n",
    "    data.to_csv(data_directory + 'train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = pd.read_csv('./data/train.csv')\n",
    "data = original_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at some general information on the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we can note we have 891 passengers, but that 'Age', 'Cabin' and 'Embarked' have some data missing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's list the data fields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the top of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can count the number of empty values. We can see that we will need to deal with 'age', 'cabin', and 'embarked'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Showing a summary of the data\n",
    "\n",
    "We can use the pandas `describe()` method to show a summary of the data. Note that this only shows numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of most likely useful fields we are missing sex and whether a passenger embarked or not. So let's code those numerically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling in (imputing) missing data\n",
    "\n",
    "For numerical data we may commonly choose to impute missing values with zero, mean or median. We will use the median for age.\n",
    "\n",
    "We will also create a new column showing which values were imputed (this may be useful information in a machine learning model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing_with_median(_series):\n",
    "    \"\"\"\n",
    "    Replace missing values in a Pandas series with median,\n",
    "    Returns a comppleted series, and a series shwoing which values are imputed\n",
    "    \"\"\"\n",
    "    # Copy the series to avoid change to the original series.\n",
    "    series = _series.copy()\n",
    "    median = series.median()\n",
    "    missing = series.isna()\n",
    "    series[missing] = median\n",
    "    \n",
    "    return series, missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age, imputed = impute_missing_with_median(data['Age'])\n",
    "data['Age'] = age\n",
    "data['AgeImputed'] = imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will impute missing embarked text with a 'missing' label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing_with_missing_label(_series):\n",
    "    \"\"\"Replace missing values in a Pandas series with the text 'missing'\"\"\"\n",
    "    # Copy the series to avoid change to the original series.\n",
    "    series = _series.copy()\n",
    "    missing = series.isna()\n",
    "    series[missing] = 'missing'\n",
    "    \n",
    "    return series, missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embarked, imputed = impute_missing_with_missing_label(data['Embarked'])\n",
    "data['Embarked'] = embarked\n",
    "data['EmbarkedImputed'] = imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sorting out cabin data\n",
    "\n",
    "Cabin data is messy! Some passengers have more than one cabin (in which case we will split out the multiple cabins and just use the first one). Cabin numbers are a letter followed by a number. We will separate out the letter and the number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cabin data from dataframe\n",
    "cabin = data['Cabin']\n",
    "\n",
    "# Set up strings to add each passenger data to\n",
    "CabinLetter = []\n",
    "CabinLetterImputed = []\n",
    "CabinNumber = []\n",
    "CabinNumberImputed = []\n",
    "\n",
    "# Convert all cabin data to string (empty cells are current stored as 'float')\n",
    "cabin = cabin.astype(str)\n",
    "\n",
    "# Iterate through rows\n",
    "for index, value in cabin.items():\n",
    "    # If cabin info is missing (string is 'nan' then add imputed data)\n",
    "    if value == 'nan':\n",
    "        CabinLetter.append('missing')\n",
    "        CabinLetterImputed.append(True)\n",
    "        CabinNumber.append(0)\n",
    "        CabinNumberImputed.append(True)\n",
    "    # Otherwise split string by spaces where there are multiple cabins\n",
    "    else:\n",
    "        # Split multiple cabins\n",
    "        cabins = value.split(' ')\n",
    "        # Take first cabin\n",
    "        use_cabin = cabins[0]\n",
    "        letter = use_cabin[0] # First letter \n",
    "        CabinLetter.append(letter)\n",
    "        CabinLetterImputed.append(False)\n",
    "        if len(use_cabin) > 1:\n",
    "            number = use_cabin[1:]\n",
    "            CabinNumber.append(number)\n",
    "            CabinNumberImputed.append(False)\n",
    "        else:\n",
    "            CabinNumber.append(0)\n",
    "            CabinNumberImputed.append(True)\n",
    "\n",
    "data['CabinLetter'] = CabinLetter\n",
    "data['CabinLetterImputed'] = CabinLetterImputed\n",
    "data['CabinNumber'] = CabinNumber\n",
    "data['CabinNumberImputed'] = CabinNumberImputed\n",
    "\n",
    "data.drop('Cabin', axis=1, inplace=True)       \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check our missing numbers totals again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding non-numerical fields.\n",
    "\n",
    "There are three types of non-numerical field:\n",
    "\n",
    "* Dichotomous, which have two, and only two, possibilities (e.g. male/female, alive/dead). These may be recoded as 0 or 1.\n",
    "* Categorical, which have any number of possibilties that cannot be ordered in any sensible way (e.g. colour of car'). Each possibility is coded seperately as 0/1 (e.g red = 0 or 1, green = 0 or 1, blue = 0 or 1). This is called 'one-hot encoding' as there will be one '1' (hot) in a set of columns (with all other values being zero).\n",
    "* Ordinal, which have any number of possibilties but which may be ordered in a sensible way and coded by order of list. For example the zise of shirts may be xs, s, m, l and xl. These may be re-coded as size 0, 1, 2, 3, 4 (or scalled in another way if appropriate).\n",
    "\n",
    "We'll look at sex first. Let's pull that out as a separate 'series'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex = data['Sex']\n",
    "sex.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From looking at the data it appears passengers are either male or female, but data can contain missing values or spelling mistakes, so let's check all the values present. An easy way to do this is to use Python's `set` command which only allows one instance of each value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(sex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's good. We have just 'female' and 'male'. Let's code a new 'male' column manually, and check the mean (the proportion of passengers who are male)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "male = data['Sex'] == 'male'\n",
    "male.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's looks reasonable. We'll add our new column to our dataframe, and remove the old 'sex' column.\n",
    "\n",
    "To remove a column we use the pandas `drop()` method. To show it is a column we specigy `axis=1`. To instruct removal from the data itself we use `inplace=True`. This is the equivalent of saying `data = data.drop()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['male'] = male\n",
    "data.drop(['Sex'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at our table now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the same with 'embarked'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embarked = data['Embarked']\n",
    "set(embarked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah, we have four possibilties!\n",
    "\n",
    "We could frame this as a series of if/elif/esle statements. That is reasonable for a few possibilties, but what if have have many? We could write our own function to 'one-hot' encode this column, but pandas can already do this for us with the `get_dummies` method.\n",
    "\n",
    "Note that we pass a couple of useful arguments: `prefix` allows us to add some text to each label, and `dummy_na=True` allows us to specifically code missing values (though we have already given them the label 'missing').\n",
    "\n",
    "As ever, it is often useful to look at the help for these methods (`help(pd.get_dummies`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embarked_coded = pd.get_dummies(embarked, prefix='Embarked')\n",
    "embarked_coded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! We'll add our new table to the data table and drop the original 'Embarked' column. Pandas `concat` method will join our dataframes.\n",
    "\n",
    "Pandas has `concat`, `merge` and `join` methods for combining dataframes\n",
    "https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data, embarked_coded], axis=1)\n",
    "data.drop(['Embarked'], axis=1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cabin_coded = pd.get_dummies(CabinLetter, prefix='CabinLetter')\n",
    "cabin_coded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's add those back to the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data, cabin_coded], axis=1)\n",
    "data.drop(['CabinLetter'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will drop the Name and Ticket column (they may perhaps be useful in some way, but we'll simplify things by remiving them)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['Name', 'Ticket']\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Having a quick look at differences between survived and non-survived passengers\n",
    "\n",
    "Phew, the data-preprocessing is done! This is often a tedious and time-consuming stage with few 'endorphin rush' rewards to be had.\n",
    "\n",
    "Let's split our data into survived and non-survived and have a quick look to see anything obvious."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = data['Survived'] == 1 # mask for survived passengers\n",
    "survived = data[mask]\n",
    "\n",
    "# Invert mask (for passengers who died\n",
    "mask = mask == False\n",
    "died = data[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's have a quick look at mean values for our two groups.\n",
    "We'll put them side by side in a new DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.DataFrame()\n",
    "summary['survived'] = survived.mean()\n",
    "summary['died'] = died.mean()\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('./data/processed_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
